{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>age</th>\n",
       "      <th>thread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>october recommendations suggestions playlists ...</td>\n",
       "      <td>20</td>\n",
       "      <td>20551.811835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>october covers thread</td>\n",
       "      <td>3</td>\n",
       "      <td>20550.578502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rock hall fame notorious b g whitney houston s...</td>\n",
       "      <td>9</td>\n",
       "      <td>580.078502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pat benatar invincible</td>\n",
       "      <td>0</td>\n",
       "      <td>106.795169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>kate bush david gilmour running hill live secr...</td>\n",
       "      <td>0</td>\n",
       "      <td>544.745169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  comments           age  \\\n",
       "0  october recommendations suggestions playlists ...        20  20551.811835   \n",
       "1                              october covers thread         3  20550.578502   \n",
       "2  rock hall fame notorious b g whitney houston s...         9    580.078502   \n",
       "3                             pat benatar invincible         0    106.795169   \n",
       "4  kate bush david gilmour running hill live secr...         0    544.745169   \n",
       "\n",
       "   thread  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1958, 4)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0\n",
       "comments    0\n",
       "age         0\n",
       "thread      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model variables X and y\n",
    "X = df['title']\n",
    "y = df['thread']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets for model creation and performance evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: title, dtype: object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "X.loc[X.isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.509202\n",
       "1    0.490798\n",
       "Name: thread, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure the data is properly stratified\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to remove a given list of words from a column of a DataFrame.\n",
    "def remove_given_words(column, given_words):\n",
    "    \n",
    "    cv = CountVectorizer(stop_words=given_words)\n",
    "    words = cv.fit_transform(column)\n",
    "    df_words = pd.DataFrame(words.toarray(), columns=cv.get_feature_names())\n",
    "    print(df_words.sum())\n",
    "    return df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider gridsearching over LR parameters\n",
    "lr = LogisticRegression()\n",
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVEC/LR Best Accuracy Score: 0.841\n",
      "CVEC/LR Training Score: 0.916\n",
      "CVEC/LR Testing Score 0.84\n"
     ]
    }
   ],
   "source": [
    "# Establish a pipeline to function as the model for gridsearching\n",
    "pipe = Pipeline([\n",
    "    \n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "    #('lr', LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "# Set the pipeline parameters that I want gridsearch to vary\n",
    "pipe_params = {\n",
    "    \n",
    "    'cvec__max_features': [100, 500, 1000],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'cvec__stop_words': [None, 'english']#,\n",
    "    #'lr__C': [1, 1e3, 1e6, 1e9]\n",
    "    \n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV, fit the model and find the best set of parameters\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "gs_model = gs.best_estimator_\n",
    "print(f'CVEC/LR Best Accuracy Score: {round(gs.best_score_, 3)}')\n",
    "print(f'CVEC/LR Training Score: {round(gs_model.score(X_train, y_train), 3)}')\n",
    "print(f'CVEC/LR Testing Score {round(gs_model.score(X_test, y_test), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying the amount and types of regularization in the model had very little effect on the scores. My original model was chosen as the best because of its simplicity and manageable amount of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF/LR Best Accuracy Score: 0.819\n",
      "TFIDF/LR Training Score: 0.951\n",
      "TFIDF/LR Testing Score 0.836\n"
     ]
    }
   ],
   "source": [
    "# Establish a pipeline to function as the model for gridsearching\n",
    "pipe2 = Pipeline([\n",
    "    \n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5))\n",
    "    \n",
    "])\n",
    "\n",
    "# Set the pipeline parameters that I want gridsearch to vary\n",
    "pipe_params2 = {\n",
    "    \n",
    "    'tfidf__max_features': [100, 500, 1000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'lr__C': [1, 1e3, 1e6, 1e9]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV, fit the model and find the best set of parameters\n",
    "gs2 = GridSearchCV(pipe2, param_grid=pipe_params2, cv=5)\n",
    "gs2.fit(X_train, y_train)\n",
    "gs_model2 = gs2.best_estimator_\n",
    "print(f'TFIDF/LR Best Accuracy Score: {round(gs2.best_score_, 3)}')\n",
    "print(f'TFIDF/LR Training Score: {round(gs_model2.score(X_train, y_train), 3)}')\n",
    "print(f'TFIDF/LR Testing Score {round(gs_model2.score(X_test, y_test), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying the amount and types of regularization in the model had a negative effect on the scores but led to a drastic decrease in overfitting. The new model varying the amount of elasticnet regularization was chosen as best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider gridsearching over BernoulliNB parameters\n",
    "nb = BernoulliNB()\n",
    "nb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVEC/BNB Best Accuracy Score: 0.834\n",
      "CVEC/BNB Training Score: 0.898\n",
      "CVEC/BNB Testing Score 0.843\n"
     ]
    }
   ],
   "source": [
    "# Establish a pipeline to function as the model for gridsearching\n",
    "pipe4 = Pipeline([\n",
    "    \n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', BernoulliNB())\n",
    "    \n",
    "])\n",
    "\n",
    "# Set the pipeline parameters that I want gridsearch to vary\n",
    "pipe_params4 = {\n",
    "    \n",
    "    'cvec__max_features': [100, 500, 1000],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'cvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV, fit the model and find the best set of parameters\n",
    "gs4 = GridSearchCV(pipe4, param_grid=pipe_params4, cv=5)\n",
    "gs4.fit(X_train, y_train)\n",
    "gs_model4 = gs4.best_estimator_\n",
    "print(f'CVEC/BNB Best Accuracy Score: {round(gs4.best_score_, 3)}')\n",
    "print(f'CVEC/BNB Training Score: {round(gs_model4.score(X_train, y_train), 3)}')\n",
    "print(f'CVEC/BNB Testing Score {round(gs_model4.score(X_test, y_test), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF/BNB Best Accuracy Score: 0.834\n",
      "TFIDF/BNB Training Score: 0.898\n",
      "TFIDF/BNB Testing Score 0.843\n"
     ]
    }
   ],
   "source": [
    "# Establish a pipeline to function as the model for gridsearching\n",
    "pipe5 = Pipeline([\n",
    "    \n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', BernoulliNB())\n",
    "    \n",
    "])\n",
    "\n",
    "# Set the pipeline parameters that I want gridsearch to vary\n",
    "pipe_params5 = {\n",
    "    \n",
    "    'tfidf__max_features': [100, 500, 1000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV, fit the model and find the best set of parameters\n",
    "gs5 = GridSearchCV(pipe5, param_grid=pipe_params5, cv=5)\n",
    "gs5.fit(X_train, y_train)\n",
    "gs_model5 = gs5.best_estimator_\n",
    "print(f'TFIDF/BNB Best Accuracy Score: {round(gs5.best_score_, 3)}')\n",
    "print(f'TFIDF/BNB Training Score: {round(gs_model5.score(X_train, y_train), 3)}')\n",
    "print(f'TFIDF/BNB Testing Score {round(gs_model5.score(X_test, y_test), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data under consideration for this project are in text form, so some form of text vectorization must occur before instantiating any sort of model. I chose to implement pipelines vectorizing the text data first using CountVectorizer and second using TfidfVectorizer. This is a binary classification problem so the first two pipelines used a Logistic Regression (LR) model and functioned as a baseline. Added benefits of using LR include interpretability, accuracy and ease of implementation. The Naive Bayes classifier was then implemented and compared to the results of LR. \n",
    "\n",
    "For more information regarding model selection, see README.md. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
